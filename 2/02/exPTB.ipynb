{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-10T07:29:38.748230Z",
     "start_time": "2024-01-10T07:29:36.255898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.train.txt ... \n",
      "Done\n",
      "말뭉치 크기: 929589\n",
      "corpus[:30] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "id_to_word[0]= aer\n",
      "id_to_word[1]= banknote\n",
      "id_to_word[2]= berlitz\n",
      "\n",
      "word_to_id['car']: 3856\n",
      "word_to_id['happy']: 4428\n",
      "word_to_id['lexus']: 7426\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import ptb\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "print('말뭉치 크기:', len(corpus))\n",
    "print('corpus[:30]', corpus[:30])\n",
    "print()\n",
    "\n",
    "print('id_to_word[0]=', id_to_word[0])\n",
    "print('id_to_word[1]=', id_to_word[1])\n",
    "print('id_to_word[2]=', id_to_word[2])\n",
    "print()\n",
    "print(\"word_to_id['car']:\", word_to_id['car'])\n",
    "print(\"word_to_id['happy']:\", word_to_id['happy'])\n",
    "print(\"word_to_id['lexus']:\", word_to_id['lexus'])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#PTB 데이터 셋 평가\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.util import most_similar, create_co_matrix, ppmi\n",
    "from dataset import ptb \n",
    "\n",
    "window_size = 2\n",
    "wordvec_size = 100\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print(\"동시발생 수 계산 ...\")\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('PPMI 계산 ...')\n",
    "W = ppmi(C, verbose=True)\n",
    "\n",
    "print('SVD 계산 ...')\n",
    "try:\n",
    "    from sklearn.utils.extmath import randomized_svd\n",
    "    U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5, random_state=None)\n",
    "except ImportError:\n",
    "    U, S, V = np.linalg.svd(W)\n",
    "    \n",
    "word_vecs = U[:, :wordvec_size]\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "336343e91a11b341"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "study",
   "language": "python",
   "display_name": "STUDY"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
